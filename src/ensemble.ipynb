{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my (JC) contribution to this project. I've implemented the code for splitting the dataset into seperate datasets that we can then use for evaulation, and hence scoring of the pre-trained models we're attempting to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize questions\n",
    "def naive_categorize_question(example):\n",
    "    question = example['question'].lower()\n",
    "    if 'date' in question:\n",
    "        return 'date'\n",
    "    if 'during' in question:\n",
    "        return 'during'\n",
    "    if 'how are' in question:\n",
    "        return 'how are'\n",
    "    if 'how big' in question or 'how large' in question:\n",
    "        return 'how big/size'\n",
    "    if 'how many' in question or 'how much' in question:\n",
    "        return 'how m/m'\n",
    "    if 'how old' in question:\n",
    "        return 'how old'\n",
    "    if 'what time' in question:\n",
    "        return 'what time'\n",
    "    if 'what' in question or 'which' in question:\n",
    "        return 'what'\n",
    "    if 'when' in question:\n",
    "        return 'when'\n",
    "    if 'where' in question:\n",
    "        return 'where'\n",
    "    if 'who' in question:\n",
    "        return 'who'\n",
    "    if 'whom' in question:\n",
    "        return 'whom'\n",
    "    if 'why' in question:\n",
    "        return 'why'\n",
    "    else:\n",
    "        return 'undefined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'what': 6595 questions\n",
      "Category 'where': 464 questions\n",
      "Category 'who': 1151 questions\n",
      "Category 'undefined': 421 questions\n",
      "Category 'how m/m': 771 questions\n",
      "Category 'during': 172 questions\n",
      "Category 'when': 710 questions\n",
      "Category 'date': 60 questions\n",
      "Category 'how old': 21 questions\n",
      "Category 'why': 148 questions\n",
      "Category 'how big/size': 12 questions\n",
      "Category 'what time': 10 questions\n",
      "Category 'how are': 35 questions\n"
     ]
    }
   ],
   "source": [
    "# Load the SQuAD dataset\n",
    "dataset = load_dataset('squad', split='validation')\n",
    "\n",
    "# Add a new field for question categories\n",
    "dataset = dataset.map(lambda entry: {\"category\": naive_categorize_question(entry)})\n",
    "\n",
    "# Split the dataset into categories\n",
    "categories = dataset.unique('category')\n",
    "categorized_datasets = {category: dataset.filter(lambda example: example['category'] == category) for category in categories}\n",
    "\n",
    "# Print out the size of each categorized dataset\n",
    "for category, subset in categorized_datasets.items():\n",
    "    print(f\"Category '{category}': {len(subset)} questions\")\n",
    "\n",
    "# If you want to save these subsets, you can do so like this:\n",
    "# for category, subset in categorized_datasets.items():\n",
    "#     subset.to_csv(f'squad_{category}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "bbc = AutoModelForQuestionAnswering.from_pretrained('bert-base-cased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating bert-base-cased...\n",
      "creating QA pipeline\n",
      "starting eval on category: how big/size\n",
      "Dataset({\n",
      "    features: ['id', 'title', 'context', 'question', 'answers', 'category'],\n",
      "    num_rows: 12\n",
      "})\n",
      "predictions finished\n",
      "{'score': 0.00016254832735285163, 'start': 267, 'end': 312, 'answer': 'and the ground. Sparks sprang from water line'}\n",
      "{'score': 0.00021144031779840589, 'start': 373, 'end': 409, 'answer': '4m customers had subscribed to BSkyB'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3194c225d39c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mreferences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Model: {model_name} Category: {category}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Exact Match (EM): {results['exact_match']:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\metric.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\metric.py\u001b[0m in \u001b[0;36madd_batch\u001b[1;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"predictions\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"references\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mintput_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36mencode_batch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m   1884\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m             \u001b[0mencoded_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1887\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1884\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m             \u001b[0mencoded_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1887\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[1;34m(schema, obj, level)\u001b[0m\n\u001b[0;32m   1227\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Got None but expected a dictionary instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         return (\n\u001b[1;32m-> 1229\u001b[1;33m             {\n\u001b[0m\u001b[0;32m   1230\u001b[0m                 \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\features\\features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1227\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Got None but expected a dictionary instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         return (\n\u001b[1;32m-> 1229\u001b[1;33m             {\n\u001b[0m\u001b[0;32m   1230\u001b[0m                 \u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\utils\\py_utils.py\u001b[0m in \u001b[0;36mzip_dict\u001b[1;34m(*dicts)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# set merge all keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Jian Cheng\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\datasets\\utils\\py_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# set merge all keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "from transformers.pipelines.pt_utils import KeyPairDataset\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "\n",
    "metric = load_metric(\"squad\")\n",
    "# Function to calculate metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    \n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Pretrained models to evaluate\n",
    "model_names = [\n",
    "    #\n",
    "    # Amadeus I'm relying on you here HAHA\n",
    "    #\n",
    "    'bert-base-cased'\n",
    "]\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name in model_names:\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    # Load the model and tokenizer\n",
    "    # model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "    # tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = bbc\n",
    "    tokenizer = tokenizer\n",
    "\n",
    "    # Create a QA pipeline\n",
    "    print(\"creating QA pipeline\")\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    # for category in categorized_datasets.keys():\n",
    "    for category in ['how big/size', 'what time']:\n",
    "        print(f\"starting eval on category: {category}\")\n",
    "        dataset = categorized_datasets[category]\n",
    "        # Making predictions and evaluating\n",
    "        print(dataset)\n",
    "        \n",
    "        predictions = []\n",
    "        for entry in dataset:\n",
    "            predictions.append(qa_pipeline(entry[\"question\"], entry[\"context\"]))\n",
    "        print(\"predictions finished\")\n",
    "        print(predictions[0])\n",
    "        print(predictions[1])\n",
    "\n",
    "        references = dataset.select_columns(['answers', 'id'])\n",
    "        results = metric.compute(predictions=predictions, references=references)\n",
    "        print(f\"Model: {model_name} Category: {category}\")\n",
    "        print(f\"Exact Match (EM): {results['exact_match']:.2f}\")\n",
    "        print(f\"F1 Score: {results['f1']:.2f}\\n\")\n",
    "\n",
    "# You would need to implement the compute_f1 function based on the SQuAD evaluation script or import it if available.\n",
    "# Also note that making predictions on the full dataset would be slow and resource-intensive;\n",
    "# you might want to batch the predictions or use a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2803937792778015, 'start': 0, 'end': 7, 'answer': 'context'}\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model=bbc, tokenizer=tokenizer)\n",
    "\n",
    "print(question_answerer(question=\"question\", context=\"context\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
